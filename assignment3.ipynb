{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loads in the different .feather datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anp_df = pd.read_feather('data/anp.feather')\n",
    "image_d_df = pd.read_feather('data/image_data.feather')\n",
    "image_m_df = pd.read_feather('data/image_metrics.feather')\n",
    "face_df = pd.read_feather('data/face.feather')\n",
    "object_df = pd.read_feather('data/object_labels.feather')\n",
    "survey_df = pd.read_feather('data/survey.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_d_df.to_csv('image_d_df.csv')\n",
    "image_m_df.to_csv('image_m_df.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_d_df = pd.read_feather('data/image_data.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding together image data, anp, object label and face.\n",
    "\n",
    "The next step is to create one dataframe, grouped per user, containing the aggregate data that was pulled from the users their instagram accounts. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## anp_df\n",
    "\n",
    "#### method:\n",
    "\n",
    "1. the anp label is dropped because it does not make sense to aggregate this. \n",
    "2. the dataframe is then split into a sentiment dataframe and an emotion dataframe for seperate processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop anp_label\n",
    "\n",
    "anp_df = anp_df.drop(['anp_label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make sentiment df\n",
    "\n",
    "anp_sent = anp_df.drop(['emotion_score', 'emotion_label'], axis = 1)\n",
    "anp_sent = pd.DataFrame(anp_sent.groupby(by='image_id', as_index=False)['anp_sentiment'].mean())\n",
    "anp_sent = anp_sent.set_index('image_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split for emotion\n",
    "\n",
    "anp_emo = anp_df.drop(['anp_sentiment'], axis = 1)\n",
    "len(anp_emo['image_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the emotion with the highest score is taken for each user\n",
    "\n",
    "ax = anp_emo.groupby(['image_id'])['emotion_score'].transform(max) == anp_emo['emotion_score']\n",
    "anp_emo = anp_emo[ax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# duplicates are removed to get only unique images\n",
    "\n",
    "anp_emo = anp_emo.drop_duplicates()\n",
    "anp_emo = anp_emo.set_index('image_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the emotion and sentiment dataframes are merged again.\n",
    "\n",
    "anp_final = anp_sent.join(anp_emo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image_d_df\n",
    "\n",
    "#### method:\n",
    "1. Thing that can not be aggregated such as image_link, etc, are dropped from the dataframe. \n",
    "2. Timestamp is changed so that only the hour from 00 - 23 is included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop unnecesarry data\n",
    "\n",
    "image_d_df = image_d_df.drop(['image_link','image_url', 'user_full_name', 'user_name'\\\n",
    "                              , 'user_website','user_profile_pic', 'user_bio', 'image_posted_time_unix'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change timestamp to be 24 hours\n",
    "\n",
    "import re\n",
    "\n",
    "def changeTime(time):\n",
    "    time = time.split()[1]\n",
    "    time = time.split(':')[0]\n",
    "    time = time.lstrip('0')\n",
    "    time = ''.join([i for i in time if re.match('[0-9]', i) is not None])\n",
    "    try: \n",
    "        return int(time)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "image_d_df['posting_time'] = image_d_df['image_posted_time'].apply(lambda x: changeTime(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set indesx to image id and drop image_posted_time\n",
    "\n",
    "image_d_df = image_d_df.set_index('image_id')\n",
    "image_d_df = image_d_df.drop('image_posted_time', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image_m_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### method: \n",
    "1. drop things that we do not need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_m_df = image_m_df.drop(['comment_count_time_created', 'like_count_time_created'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_m_df = image_m_df.set_index('image_id')\n",
    "image_m_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## object_df\n",
    "\n",
    "#### method:\n",
    "1. Only take the object with highest confidence level for each picture. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# take object with max confidence\n",
    "\n",
    "group = object_df.groupby(['image_id', 'data_amz_label'])['data_amz_label_confidence'].transform(max) == object_df['data_amz_label_confidence']\n",
    "object_df = object_df[group]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## face_df: emotion\n",
    "\n",
    "#### method:\n",
    "\n",
    "1. first a split is made for face emotion\n",
    "2. images are grouped by image_id and face_id, for each image we check how many faces have a certain emotion. The highest number of face emotions is picked as the image emotion.\n",
    "3. If we have an equal number (let's say 1 joy face and 1 sad face, the emotion with the highest confidence level is selected.) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first, split for face emotion\n",
    "\n",
    "face_emo = face_df[['image_id', 'face_id', 'face_emo', 'emo_confidence']]\n",
    "ab = face_emo.groupby(['image_id', 'face_id'])['emo_confidence'].transform(max) == face_emo['emo_confidence']\n",
    "face_emo = face_emo[ab]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# get unique image_id's\n",
    "UniqueNames = face_emo.image_id.unique()\n",
    "\n",
    "def changeDataFrame(df):\n",
    "    \n",
    "    new_list = []\n",
    "    \n",
    "    for _id in UniqueNames:\n",
    "        \n",
    "        # check whether one emotion is found more often than others\n",
    "        \n",
    "        df_temp = face_emo.loc[face_emo['image_id'] == _id]\n",
    "        counts = df_temp['face_emo'].value_counts().to_dict()\n",
    "        maximum = sorted(counts.items(), key=operator.itemgetter(1))\n",
    "\n",
    "        # if there is an equal number of emotions look at confidence.\n",
    "        \n",
    "        if len(maximum) > 1:\n",
    "            if maximum[0][1] == maximum[1][1]:\n",
    "\n",
    "                group = df_temp.groupby(['image_id'])['emo_confidence'].transform(max) == df_temp['emo_confidence']\n",
    "                new_slice = df_temp[group]\n",
    "                new_list.append([new_slice['image_id'].values[0], new_slice['face_emo'].values[0]])  \n",
    "                \n",
    "            else: \n",
    "                new_list.append([df_temp['image_id'].values[0], maximum[0][0]])\n",
    "\n",
    "        # else select the emotion that is present on most faces.\n",
    "        \n",
    "        else: \n",
    "            new_list.append([df_temp['image_id'].values[0], maximum[0][0]])\n",
    "            \n",
    "    output_df = pd.DataFrame(new_list, columns=['image_id','face_emo'])\n",
    "    \n",
    "    return output_df\n",
    "    \n",
    "\n",
    "new_emo = changeDataFrame(face_emo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## face_df: finding the number of faces\n",
    "\n",
    "#### method:\n",
    "1. aggregate number of faces per picture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# take image_id, face_id and emo_confidence\n",
    "\n",
    "face_no_df = face_df[['image_id', 'face_id', 'emo_confidence']]\n",
    "group = face_no_df.groupby(['image_id', 'face_id'])['emo_confidence'].transform(max) == face_no_df['emo_confidence']\n",
    "face_no_df = face_no_df[group].drop('emo_confidence', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# aggregate for number of faces \n",
    "face_count_df = pd.DataFrame(face_no_df['image_id'].value_counts())\n",
    "face_count_df['no_of_faces'] = face_count_df['image_id']\n",
    "face_count_df = face_count_df.drop('image_id', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## face_df: find average age per picture\n",
    "\n",
    "1. select face age low and high\n",
    "2. take the mean value for each face\n",
    "3. take the mean of those values for each picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "face_df_age = face_df[['image_id', 'face_age_range_low', 'face_age_range_high']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking mean per face\n",
    "face_df_age['average_age'] = (face_df_age['face_age_range_low'] + face_df_age['face_age_range_high'])/2\n",
    "face_df_age\n",
    "\n",
    "# taking mean per picture\n",
    "average_age_df = pd.DataFrame(face_df_age.groupby('image_id')['average_age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# object_df.to_csv('object.csv')\n",
    "# face_df.to_csv('face.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# survey_df.to_csv('survey.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_d_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge different dataframes\n",
    "\n",
    "1. join different dataframes by image_id\n",
    "2. aggregate for user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge different dataframes\n",
    "df1 = anp_final.join(image_d_df)\n",
    "df2 = df1.join(face_count_df)\n",
    "df3 = df2.join(average_age_df)\n",
    "df4 = df3.join(image_m_df)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "' TODO\n",
    "' Also join object dataframe and new_emo dataframe\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_df = df4.drop(['emotion_label', 'emotion_score', 'image_filter'], axis=1)\n",
    "quant_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_df = quant_df.groupby(by='user_id').mean()\n",
    "# quant_df.to_csv('analysisfile.csv')\n",
    "quant_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quant_df.to_csv('analysis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: try to get smile percentage per picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes all the face smiles where the confidence level is more than 80 percent\n",
    "face_smile_df = face_df.loc[face_df['face_smile_confidence'] > 80]\n",
    "\n",
    "# make dataframe split to include smile\n",
    "face_smile_df = face_smile_df[['image_id', 'face_smile', 'face_id']]\n",
    "\n",
    "# drop duplicate values\n",
    "face_smile_df = face_smile_df.drop_duplicates()\n",
    "face_smile_df = face_smile_df.drop('face_id', axis=1)\n",
    "\n",
    "group = face_smile_df.groupby(['image_id', 'face_smile'])['face_smile'].count()\n",
    "group = pd.DataFrame(group / group.groupby(level=0).sum())\n",
    "# face_smile_df[group]\n",
    "\n",
    "group\n",
    "# face_smile_df = group.loc[group['face_smile'] == True]\n",
    "# face_smile_df\n",
    "\n",
    "\n",
    "# face_smile_df = face_smile_df.groupby(by='image_id')['face_smile'].count()\n",
    "# face_smile_df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge survey dataframe and analysis dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "survey_df = pd.read_feather('data/survey.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "survey_df['insta_user_id'] = survey_df['insta_user_id'].apply(lambda x: str(int(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "survey_df = survey_df.set_index('insta_user_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regr_df = quant_df.join(survey_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "regr_df = regr_df.drop(['A_2', 'N_1', 'P_1', 'E_1', 'A_1',\n",
    "       'H_1', 'M_1', 'R_1', 'M_2', 'E_2', 'LON', 'H_2', 'P_2', 'N_2', 'A_3',\n",
    "       'N_3', 'E_3', 'H_3', 'R_2', 'M_3', 'R_3', 'P_3', 'HAP','network_id', 'P', 'E', 'R', 'M', 'A', 'start_q', 'end_q', 'private_account'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_d_df['emotion)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "%matplotlib inline\n",
    "\n",
    "scatter_matrix(regr_df[['PERMA','anp_sentiment', 'data_memorability',\n",
    "       'user_followed_by', 'user_follows', 'user_posted_photos',\n",
    "       'posting_time', 'no_of_faces', 'average_age','imagecount']], alpha=1.0, figsize=(20, 20), diagonal='kde')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regr_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take two variables\n",
    "X = regr_df[[\"user_posted_photos\"]]\n",
    "y = regr_df[[\"PERMA\"]]\n",
    "\n",
    "# create training and testing vars\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a LinearRegression object\n",
    "lm = LinearRegression()\n",
    "\n",
    "# Fit curve\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction\n",
    "y_predict = lm.predict(X_test)\n",
    "\n",
    "# Show metrics\n",
    "print('Coefficients: \\n', lm.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, y_predict))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, y_predict))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# results from regression\n",
    "\n",
    "#### 1. PERMA ~ anp_sentiment\n",
    "\n",
    "Correlation: 0.21477\n",
    "\n",
    "Coefficients: \n",
    " [[ 4.68761213]]\n",
    "Mean squared error: 3.59\n",
    "Variance score: 0.03\n",
    "\n",
    "#### 2. PERMA ~ posting_time\n",
    "\n",
    "correlation: -0.205047\n",
    "\n",
    "Coefficients: \n",
    " [[-0.12492383]]\n",
    "Mean squared error: 2.93\n",
    "Variance score: -0.08\n",
    "\n",
    "#### 3. PERMA ~ data_memorability\n",
    "\n",
    "correlation: 0.195383\n",
    "\n",
    "Coefficients: \n",
    " [[ 9.01465037]]\n",
    "Mean squared error: 1.98\n",
    "Variance score: -0.04\n",
    "\n",
    "#### 4. PERMA ~ imagecount\t\n",
    "\n",
    "correlation: -0.112792\n",
    "\n",
    "Coefficients: \n",
    " [[-0.00031376]]\n",
    "Mean squared error: 3.32\n",
    "Variance score: 0.04\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
